{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載Hugging face shibing624/bert4ner-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 17:04:23,991 - INFO - 正在載入模型: shibing624/bert4ner-base-chinese\n",
      "2024-12-18 17:04:24,253 - INFO - 模型載入完成\n",
      "2024-12-18 17:04:24,253 - INFO - 處理文本: 中華民國民眾黨主席柯文哲涉政治獻金假帳案，調查局北機站清查金流發現，民眾黨利用「網紅帶貨」銷售手法，先藉由「學姐」黃瀞瑩等人高知名度，吸引選民捐贈政治獻金，再用「折扣碼」發放KP競選小物，進而從中抽佣分潤，抽佣的錢疑來自政治獻金，涉及違反政治獻金法，黃瀞瑩與「戰狼小姐姐」陳智菡、許甫、吳怡萱等4人恐由證人轉列被告偵辦\n",
      "2024-12-18 17:04:24,288 - INFO - 識別結果: [['中 華 民 國 民 眾 黨', 'ORG'], ['柯 文 哲', 'PER'], ['黃 瀞 瑩', 'PER'], ['黃 瀞 瑩', 'PER'], ['陳 智 菡', 'PER'], ['許 甫', 'PER'], ['吳 怡 萱', 'PER']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_model(model_name: str = \"shibing624/bert4ner-base-chinese\"):\n",
    "    \"\"\"\n",
    "    設置和初始化模型\n",
    "    \n",
    "    Args:\n",
    "        model_name: Hugging Face 模型名稱\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"正在載入模型: {model_name}\") \n",
    "        classifier = pipeline(\n",
    "            \"token-classification\",\n",
    "            model=model_name,\n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "        logger.info(\"模型載入完成\")\n",
    "        return classifier\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"模型載入失敗: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def process_text(text: str, classifier) -> list:\n",
    "    \"\"\"\n",
    "    處理文本並進行命名實體識別\n",
    "    \n",
    "    Args:\n",
    "        text: 輸入文本\n",
    "        classifier: NER pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"處理文本: {text}\")\n",
    "        results = classifier(text)\n",
    "        \n",
    "        # 整理結果\n",
    "        entities = []\n",
    "        for item in results:\n",
    "            entities.append([\n",
    "                item['word'],\n",
    "                item['entity_group']\n",
    "            ])\n",
    "        \n",
    "        return entities\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"文本處理失敗: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 初始化模型\n",
    "        classifier = setup_model()\n",
    "        \n",
    "        # 測試文本\n",
    "        sample_text = \"中華民國民眾黨主席柯文哲涉政治獻金假帳案，調查局北機站清查金流發現，民眾黨利用「網紅帶貨」銷售手法，先藉由「學姐」黃瀞瑩等人高知名度，吸引選民捐贈政治獻金，再用「折扣碼」發放KP競選小物，進而從中抽佣分潤，抽佣的錢疑來自政治獻金，涉及違反政治獻金法，黃瀞瑩與「戰狼小姐姐」陳智菡、許甫、吳怡萱等4人恐由證人轉列被告偵辦\"\n",
    "        \n",
    "        # 處理文本\n",
    "        entities = process_text(sample_text, classifier)\n",
    "        \n",
    "        logger.info(f\"識別結果: {entities}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序執行出錯: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引用本地端\n",
    "\n",
    "設置模型路徑\n",
    "\n",
    "model_path = \"./examples/outputs/cner_bertsoftmax/best_model\"  # 請確保這個路徑指向你的模型目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 17:03:55,110 - INFO - 正在從本地載入模型: ./examples/outputs/cner_bertspan/best_model\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ./examples/outputs/cner_bertspan/best_model and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-12-18 17:03:55,158 - INFO - 模型載入完成\n",
      "2024-12-18 17:03:55,159 - INFO - 處理文本: 您好，我是常建良有多模態客服機器人開發應用，(北京國科會、玉山、電商客服開發經驗)。支援語音、文字、檔案上傳\n",
      "2024-12-18 17:03:55,175 - INFO - 識別結果: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_model_config(model_path: str):\n",
    "    \"\"\"\n",
    "    載入模型配置\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config_path = os.path.join(model_path, \"config.json\")\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"載入配置文件失敗: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def setup_model(model_path: str = \"./best_model\"):\n",
    "    \"\"\"\n",
    "    從本地檔案載入模型\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"正在從本地載入模型: {model_path}\")\n",
    "        \n",
    "        # 檢查必要文件\n",
    "        required_files = [\n",
    "            \"config.json\",\n",
    "            \"model.safetensors\",  # 使用 safetensors 而不是 pytorch_model.bin\n",
    "            \"tokenizer_config.json\",\n",
    "            \"vocab.txt\"\n",
    "        ]\n",
    "        \n",
    "        for file in required_files:\n",
    "            file_path = os.path.join(model_path, file)\n",
    "            if not os.path.exists(file_path):\n",
    "                logger.warning(f\"注意: 找不到文件: {file}\")\n",
    "        \n",
    "        # 載入 tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        \n",
    "        # 載入模型\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_path,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        \n",
    "        # 設置為評估模式\n",
    "        model.eval()\n",
    "        \n",
    "        logger.info(\"模型載入完成\")\n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"模型載入失敗: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def process_text(text: str, model, tokenizer) -> list:\n",
    "    \"\"\"\n",
    "    處理文本並進行命名實體識別\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"處理文本: {text}\")\n",
    "        \n",
    "        # 讀取標籤映射\n",
    "        config = load_model_config(model.config.name_or_path)\n",
    "        id2label = config.get('id2label', {})\n",
    "        \n",
    "        # 對文本進行編碼\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # 進行預測\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=2)\n",
    "        \n",
    "        # 解碼結果\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        predictions = predictions[0].tolist()\n",
    "        \n",
    "        # 整理實體\n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "        \n",
    "        for token, pred_id in zip(tokens, predictions):\n",
    "            if token in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "                continue\n",
    "                \n",
    "            label = id2label.get(str(pred_id), 'O')\n",
    "            \n",
    "            if label.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append([''.join(current_entity), current_label])\n",
    "                current_entity = [token.replace('##', '')]\n",
    "                current_label = label[2:]\n",
    "            elif label.startswith('I-') and current_entity:\n",
    "                current_entity.append(token.replace('##', ''))\n",
    "            elif label == 'O':\n",
    "                if current_entity:\n",
    "                    entities.append([''.join(current_entity), current_label])\n",
    "                    current_entity = []\n",
    "                    current_label = None\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append([''.join(current_entity), current_label])\n",
    "        \n",
    "        return entities\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"文本處理失敗: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 設置模型路徑\n",
    "        model_path = \"./examples/outputs/cner_bertspan/best_model\"\n",
    "        \n",
    "        # 檢查模型目錄是否存在\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"找不到模型目錄: {model_path}\")\n",
    "        \n",
    "        # 初始化模型\n",
    "        model, tokenizer = setup_model(model_path)\n",
    "        \n",
    "        # 測試文本\n",
    "        sample_text = \"您好，我是常建良有多模態客服機器人開發應用，(北京國科會、玉山、電商客服開發經驗)。支援語音、文字、檔案上傳\"\n",
    "        \n",
    "        # 處理文本\n",
    "        entities = process_text(sample_text, model, tokenizer)\n",
    "        \n",
    "        logger.info(f\"識別結果: {entities}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序執行出錯: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loguru'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnerpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NERModel\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m NERModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshibing624/bert4ner-base-chinese\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [ \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m李明在上海的騰訊公司擔任工程師\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m ]\n",
      "File \u001b[0;32m~/projects/nerpy/nerpy/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnerpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnerpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_file\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m http_get, get_file\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnerpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mner_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NERModel\n",
      "File \u001b[0;32m~/projects/nerpy/nerpy/ner_model.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseqeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     classification_report,\n\u001b[1;32m     22\u001b[0m     f1_score,\n\u001b[1;32m     23\u001b[0m     precision_score,\n\u001b[1;32m     24\u001b[0m     recall_score,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseqeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence_labeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_entities\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'loguru'"
     ]
    }
   ],
   "source": [
    "from nerpy import NERModel\n",
    "\n",
    "model = NERModel(\"bert\", \"shibing624/bert4ner-base-chinese\")\n",
    "sentences = [ \n",
    "    \"李明在上海的騰訊公司擔任工程師\"\n",
    "]\n",
    "# set split_on_space=False if you use Chinese text\n",
    "predictions, raw_outputs, entities = model.predict(sentences, split_on_space=False)\n",
    "print(predictions, entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
